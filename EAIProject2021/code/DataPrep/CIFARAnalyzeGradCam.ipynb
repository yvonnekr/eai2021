{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb40755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f7bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../../data/Modelling/complex_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cf5a279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               262144    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,234\n",
      "Trainable params: 551,338\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "976e879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "last_conv_layer_name=\"dropout_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8187d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1d30fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(\"../../data/Processed/truckLiquid.png\", target_size=(32, 32))\n",
    "# convert to array\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "# reshape into a single sample with 3 channels\n",
    "img = img.reshape(1, 32, 32, 3)\n",
    "# prepare pixel data\n",
    "img = img.astype('float32')\n",
    "img = img / 255.0\n",
    "\n",
    "result = model.predict_classes(img)\n",
    "print(result[0])\n",
    "print(class_names[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9542b2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x270e21ce5c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove last layer's softmax\n",
    "model.layers[-1].activation = None\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9b1624d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDpTqTx5Zbd2BPUDrUttLczksIpQx6ArxWh/wAJCjM0cTWaNz8u4sR+QFZn/CQXEeoFXe2ePCDaIypBZiuQcn2rP+01a6RdLDynuay28xQFlwcc0hjYdq4lvFWosZ5E8koCVId2ByD6j1/pWn4f1q+nKzXqQraSOI/9czurdjgjgVvgsXLE7xsY1mqTs2eRQeJtUjQmS7BO3fh2GT14x/SraeIb2O5kNzsLhEcFHyCFO7qPc12ixxuwBQ4+v/1qZqPhuw1CAmRCr4wGXFR9SjJWOv666T0RBY6zDfaLPdLarhOXLorc7eTz+H5VW0y/jvNQVYIbd2Qb2zboMAehAH86yhoOrWQMFnrTRwjoDECav6VZXNiP39ws7Zzu8vaQfzrDC4D6u5JfL+rCxVVYizP/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_and_display_gradcam(heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = tf.keras.preprocessing.image.load_img(\"../../data/Processed/truckLiquid.png\", target_size=(32, 32))\n",
    "    # convert to array\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f8469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
